{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1764c5da",
   "metadata": {},
   "source": [
    "### Problem 1 (ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19bdbe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-Layer NN Training Error: 0.04340313295600554\n",
      "Optimized Weights (2-Layer NN): [3.61214404e-19 1.27374368e-03 9.98726256e-01]\n",
      "1-Layer NN Training Error: 0.036739220525162035\n",
      "Optimized Weights (1-Layer NN): [0.13065422 0.86934578]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "np.random.seed(42)\n",
    "n = 1000000\n",
    "x = np.random.normal(0, 1, n)\n",
    "y_true = sigmoid(x)\n",
    "\n",
    "def neural_network_2_layers(weights, x):\n",
    "    w0, w1, w2 = weights\n",
    "    z0 = w0 * x\n",
    "    h1 = sigmoid(z0)\n",
    "    z1 = w1 * h1\n",
    "    h2 = sigmoid(z1)\n",
    "    z2 = w2 * h2\n",
    "    y_pred = z2\n",
    "    return y_pred\n",
    "\n",
    "def loss_function_2_layers(weights, x, y_true):\n",
    "    y_pred = neural_network_2_layers(weights, x)\n",
    "    loss = np.mean((y_pred - y_true) ** 2)\n",
    "    return loss\n",
    "\n",
    "def constraint_weights(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "def constraint_non_negative(weights):\n",
    "    return weights\n",
    "\n",
    "initial_weights_2_layers = np.array([1/3, 1/3, 1/3])\n",
    "constraints_2_layers = [{'type': 'eq', 'fun': constraint_weights}, {'type': 'ineq', 'fun': constraint_non_negative}]\n",
    "result_2_layers = minimize(loss_function_2_layers, initial_weights_2_layers, constraints=constraints_2_layers, args=(x, y_true))\n",
    "print(\"2-Layer NN Training Error:\", result_2_layers.fun)\n",
    "print(\"Optimized Weights (2-Layer NN):\", result_2_layers.x / np.sum(result_2_layers.x))\n",
    "\n",
    "\n",
    "def neural_network_1_layer(weights, x):\n",
    "    w0, w1 = weights\n",
    "    z0 = w0 * x\n",
    "    h1 = sigmoid(z0)\n",
    "    z1 = w1 * h1\n",
    "    y_pred = z1\n",
    "    return y_pred\n",
    "\n",
    "def loss_function_1_layer(weights, x, y_true):\n",
    "    y_pred = neural_network_1_layer(weights, x)\n",
    "    loss = np.mean((y_pred - y_true) ** 2)\n",
    "    return loss\n",
    "\n",
    "initial_weights_1_layer = np.array([0.5, 0.5])\n",
    "constraints_1_layer = [{'type': 'eq', 'fun': constraint_weights}, {'type': 'ineq', 'fun': constraint_non_negative}]\n",
    "result_1_layer = minimize(loss_function_1_layer, initial_weights_1_layer, constraints=constraints_1_layer, args=(x, y_true))\n",
    "print(\"1-Layer NN Training Error:\", result_1_layer.fun)\n",
    "print(\"Optimized Weights (1-Layer NN):\", result_1_layer.x / np.sum(result_1_layer.x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e12e98",
   "metadata": {},
   "source": [
    "In this scenario, where the true data generation process follows a simple sigmoid function and weights are constrained to sum to 1 with non-negative values, adding an extra layer to the neural network increases training error likely because the additional layer introduces unnecessary complexity, leading to overfitting and fitting noise rather than capturing the inherent simplicity of the data distribution. The constraints and simplicity of the data favor a single-layer model, and the additional parameters in the two-layer model hinder its ability to generalize effectively, resulting in higher training error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac475f",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcb4ce7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.877857</td>\n",
       "      <td>0.311140</td>\n",
       "      <td>1.945940</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.829943</td>\n",
       "      <td>0.175592</td>\n",
       "      <td>1.294219</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.091079</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.427715</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.247564</td>\n",
       "      <td>5.600044</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44.190936</td>\n",
       "      <td>0.566486</td>\n",
       "      <td>2.222767</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distance_from_home  distance_from_last_transaction  \\\n",
       "0           57.877857                        0.311140   \n",
       "1           10.829943                        0.175592   \n",
       "2            5.091079                        0.805153   \n",
       "3            2.247564                        5.600044   \n",
       "4           44.190936                        0.566486   \n",
       "\n",
       "   ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                        1.945940                1          1   \n",
       "1                        1.294219                1          0   \n",
       "2                        0.427715                1          0   \n",
       "3                        0.362663                1          1   \n",
       "4                        2.222767                1          1   \n",
       "\n",
       "   used_pin_number  online_order  fraud  \n",
       "0                0             0      0  \n",
       "1                0             0      0  \n",
       "2                0             1      0  \n",
       "3                0             1      0  \n",
       "4                0             1      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt \n",
    "path=\"/Users/zhangyuanzhuo/425 ML\"\n",
    "import os\n",
    "os.chdir(path)\n",
    "df = pd.read_csv(\"card_transdata-1.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b0a3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "X = df.drop('fraud', axis=1)\n",
    "categorical_features_indices = [False, False, False, True, True,True,True]\n",
    "y = df['fraud']\n",
    "\n",
    "X_train = X.iloc[:500000,:]\n",
    "y_train = y.iloc[:500000]\n",
    "X_test = X.iloc[500000:,:]\n",
    "y_test = y.iloc[500000:]\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9295841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1), \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = NeuralNetwork(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e38871d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Accuracy: 94.60%, Average Loss: 0.1263, F1 score: 0.6184\n",
      "Epoch 2/10\n",
      "Accuracy: 95.10%, Average Loss: 0.1296, F1 score: 0.6370\n",
      "Epoch 3/10\n",
      "Accuracy: 96.23%, Average Loss: 0.0894, F1 score: 0.7446\n",
      "Epoch 4/10\n",
      "Accuracy: 96.49%, Average Loss: 0.0840, F1 score: 0.7765\n",
      "Epoch 5/10\n",
      "Accuracy: 96.08%, Average Loss: 0.1227, F1 score: 0.7258\n",
      "Epoch 6/10\n",
      "Accuracy: 96.89%, Average Loss: 0.0754, F1 score: 0.8010\n",
      "Epoch 7/10\n",
      "Accuracy: 96.64%, Average Loss: 0.0744, F1 score: 0.7690\n",
      "Epoch 8/10\n",
      "Accuracy: 94.48%, Average Loss: 0.1703, F1 score: 0.7484\n",
      "Epoch 9/10\n",
      "Accuracy: 97.09%, Average Loss: 0.0693, F1 score: 0.8159\n",
      "Epoch 10/10\n",
      "Accuracy: 96.92%, Average Loss: 0.0705, F1 score: 0.7929\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "loss_fn = nn.BCEWithLogitsLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch).squeeze()\n",
    "        y_batch = y_batch.float() \n",
    "        loss = loss_fn(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    test_loss = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            predictions = model(X_batch).squeeze()\n",
    "\n",
    "            y_batch = y_batch.float()\n",
    "\n",
    "            test_loss += loss_fn(predictions, y_batch).item()\n",
    "            predicted_labels = (torch.sigmoid(predictions) >= 0.5).float()\n",
    "\n",
    "            y_true.extend(y_batch.cpu().numpy())\n",
    "            y_pred.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "            correct += (predicted_labels == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    average_loss = test_loss / len(dataloader)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    return accuracy, average_loss, f1\n",
    " \n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    accuracy, average_loss, f1 = test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%, Average Loss: {average_loss:.4f}, F1 score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610e4fbd",
   "metadata": {},
   "source": [
    "The result is worse than the simple decision tree becasue of lower F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d971e7b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
